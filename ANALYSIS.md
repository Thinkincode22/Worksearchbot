# üîç –ê–Ω–∞–ª—ñ–∑ –∫–æ–¥—É WorkSearchBot

## üîí –ë–ï–ó–ü–ï–ö–ê (Security Vulnerabilities)

### 1. SQL Injection —á–µ—Ä–µ–∑ ILIKE –∑–∞–ø–∏—Ç–∏ ‚ùå –ö–†–ò–¢–ò–ß–ù–û

**–ü—Ä–æ–±–ª–µ–º–∞:** –£ —Ñ–∞–π–ª—ñ `bot/handlers/search.py` (—Ä—è–¥–∫–∏ 64, 65, 148-152, 179-183) –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –Ω–µ–±–µ–∑–ø–µ—á–Ω–∞ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü—ñ—è —Ä—è–¥–∫—ñ–≤ –¥–ª—è ILIKE –∑–∞–ø–∏—Ç—ñ–≤.

**–í—Ä–∞–∑–ª–∏–≤—ñ—Å—Ç—å:**
```python
# –ù–ï–ë–ï–ó–ü–ï–ß–ù–û - SQL Injection
JobListing.title.ilike(f"%{kw}%")
JobListing.description.ilike(f"%{query_text}%")
```

**–í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:**
```python
# –ë–ï–ó–ü–ï–ß–ù–û - SQLAlchemy –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –µ–∫—Ä–∞–Ω—É—î –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
from sqlalchemy import func

# –ó–∞–º—ñ—Å—Ç—å:
JobListing.title.ilike(f"%{kw}%")

# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ:
JobListing.title.ilike("%" + kw + "%")  # SQLAlchemy –±–µ–∑–ø–µ—á–Ω–æ –æ–±—Ä–æ–±–ª—è—î —Ü–µ

# –ê–±–æ –¥–ª—è –±—ñ–ª—å—à —Å–∫–ª–∞–¥–Ω–∏—Ö –≤–∏–ø–∞–¥–∫—ñ–≤:
from sqlalchemy import bindparam
db_query = db_query.filter(
    JobListing.title.op('ILIKE')(bindparam('keyword'))
).params(keyword=f"%{kw}%")
```

---

### 2. –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–æ–≥–æ –≤–≤–æ–¥—É ‚ùå –í–ò–°–û–ö–ò–ô –†–ò–ó–ò–ö

**–ü—Ä–æ–±–ª–µ–º–∞:** –£ —Ñ–∞–π–ª—ñ `config/settings.py` (—Ä—è–¥–æ–∫ 32) –≤—ñ–¥—Å—É—Ç–Ω—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—è —Ñ–æ—Ä–º–∞—Ç—É –¥–ª—è `ADMIN_USER_IDS`.

**–í—Ä–∞–∑–ª–∏–≤—ñ—Å—Ç—å:**
```python
# –ù–ï–ë–ï–ó–ü–ï–ß–ù–û - –º–æ–∂–µ –≤–∏–∫–ª–∏–∫–∞—Ç–∏ ValueError
return [int(uid.strip()) for uid in self.ADMIN_USER_IDS.split(",") if uid.strip().isdigit()]
```

**–í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:**
```python
# –ë–ï–ó–ü–ï–ß–ù–û
@property
def admin_ids_list(self) -> List[int]:
    """–ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ ID –∞–¥–º—ñ–Ω—ñ–≤ –∑ –≤–∞–ª—ñ–¥–∞—Ü—ñ—î—é"""
    if not self.ADMIN_USER_IDS:
        return []
    
    result = []
    for uid in self.ADMIN_USER_IDS.split(","):
        uid = uid.strip()
        if uid.isdigit():
            try:
                user_id = int(uid)
                # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –¥—ñ–∞–ø–∞–∑–æ–Ω—É Telegram ID (–ø–æ–∑–∏—Ç–∏–≤–Ω—ñ —á–∏—Å–ª–∞ –¥–æ 2^63)
                if 0 < user_id < 2**63:
                    result.append(user_id)
                else:
                    logger.warning(f"Invalid admin ID (out of range): {uid}")
            except (ValueError, OverflowError) as e:
                logger.warning(f"Invalid admin ID: {uid}, error: {e}")
    return result
```

---

### 3. –í—ñ–¥–∫—Ä–∏—Ç–∏–π –¥–æ—Å—Ç—É–ø –¥–æ —Å–µ–∫—Ä–µ—Ç–Ω–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤ ‚ùå –ö–†–ò–¢–ò–ß–ù–û

**–ü—Ä–æ–±–ª–µ–º–∞:** –£ —Ñ–∞–π–ª—ñ `config/settings.py` (—Ä—è–¥–æ–∫ 49) –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è TELEGRAM_BOT_TOKEN —è–∫ fallback –¥–ª—è WEBHOOK_SECRET_TOKEN.

**–í—Ä–∞–∑–ª–∏–≤—ñ—Å—Ç—å:**
```python
# –ù–ï–ë–ï–ó–ü–ï–ß–ù–û - —Ç–æ–∫–µ–Ω –±–æ—Ç–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è —è–∫ —Å–µ–∫—Ä–µ—Ç
WEBHOOK_SECRET_TOKEN: str = os.getenv("WEBHOOK_SECRET_TOKEN", TELEGRAM_BOT_TOKEN)
```

**–í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:**
```python
# –ë–ï–ó–ü–ï–ß–ù–û - –≥–µ–Ω–µ—Ä—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π —Å–µ–∫—Ä–µ—Ç
import secrets

WEBHOOK_SECRET_TOKEN: str = os.getenv(
    "WEBHOOK_SECRET_TOKEN", 
    secrets.token_urlsafe(32)  # –ì–µ–Ω–µ—Ä—É—î–º–æ –≤–∏–ø–∞–¥–∫–æ–≤–∏–π —Ç–æ–∫–µ–Ω
)

# –ê–±–æ —É –≤–∏–ø–∞–¥–∫—É —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–±–µ—Ä–µ–≥—Ç–∏ –¥–ª—è —Ä–µ—Å—Ç–∞—Ä—Ç—É:
@property
def webhook_secret_token(self) -> str:
    token = os.getenv("WEBHOOK_SECRET_TOKEN")
    if not token:
        token = secrets.token_urlsafe(32)
        logger.warning("WEBHOOK_SECRET_TOKEN not set, generated: Store this in .env file!")
        logger.info(f"Add to .env: WEBHOOK_SECRET_TOKEN={token}")
    return token
```

---

### 4. –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å rate limiting –Ω–∞ —Ä—ñ–≤–Ω—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ ‚ö†Ô∏è –°–ï–†–ï–î–ù–Ü–ô –†–ò–ó–ò–ö

**–ü—Ä–æ–±–ª–µ–º–∞:** –£ —Ñ–∞–π–ª—ñ `config/settings.py` –≤–∏–∑–Ω–∞—á–µ–Ω—ñ –ª—ñ–º—ñ—Ç–∏, –∞–ª–µ –≤–æ–Ω–∏ –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –≤ –∫–æ–¥—ñ.

**–í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:** –î–æ–¥–∞–π—Ç–µ middleware –¥–ª—è rate limiting:

```python
# bot/middlewares/rate_limit.py
from telegram import Update
from telegram.ext import ContextTypes
from datetime import datetime, timedelta
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)

class RateLimiter:
    def __init__(self, max_requests: int = 30, time_window: int = 60):
        self.max_requests = max_requests
        self.time_window = timedelta(seconds=time_window)
        self.user_requests = defaultdict(list)
    
    def is_allowed(self, user_id: int) -> bool:
        now = datetime.now()
        
        # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ –∑–∞–ø–∏—Ç–∏
        self.user_requests[user_id] = [
            req_time for req_time in self.user_requests[user_id]
            if now - req_time < self.time_window
        ]
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –ª—ñ–º—ñ—Ç
        if len(self.user_requests[user_id]) >= self.max_requests:
            return False
        
        self.user_requests[user_id].append(now)
        return True

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤ main.py:
rate_limiter = RateLimiter(
    max_requests=settings.MAX_REQUESTS_PER_MINUTE,
    time_window=60
)

async def rate_limit_middleware(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    
    if not rate_limiter.is_allowed(user_id):
        await update.message.reply_text(
            "‚ö†Ô∏è –ó–∞–Ω–∞–¥—Ç–æ –±–∞–≥–∞—Ç–æ –∑–∞–ø–∏—Ç—ñ–≤. –ó–∞—á–µ–∫–∞–π—Ç–µ —Ö–≤–∏–ª–∏–Ω—É."
        )
        return  # –ë–ª–æ–∫—É—î–º–æ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
    
    # –ü—Ä–æ–¥–æ–≤–∂—É—î–º–æ –æ–±—Ä–æ–±–∫—É
    return await context.dispatcher.process_update(update)
```

---

### 5. –ü–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∞ DoS —á–µ—Ä–µ–∑ –Ω–µ–æ–±–º–µ–∂–µ–Ω–∏–π –∑–∞–ø–∏—Ç –¥–æ –ë–î ‚ö†Ô∏è –°–ï–†–ï–î–ù–Ü–ô –†–ò–ó–ò–ö

**–ü—Ä–æ–±–ª–µ–º–∞:** –£ —Ñ–∞–π–ª—ñ `bot/handlers/search.py` (—Ä—è–¥–æ–∫ 190) –∑–∞–ø–∏—Ç –æ–±–º–µ–∂–µ–Ω–∏–π —Ç—ñ–ª—å–∫–∏ 50 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏, –∞–ª–µ –Ω–µ–º–∞—î –æ–±–º–µ–∂–µ–Ω–Ω—è –Ω–∞ —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –∑–∞–ø–∏—Ç—É.

**–í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:**
```python
# –î–æ–¥–∞–π—Ç–µ —Ç–∞–π–º–∞—É—Ç —Ç–∞ –æ–±–º–µ–∂–µ–Ω–Ω—è –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤
from sqlalchemy import event
from sqlalchemy.engine import Engine
import time

# –í database.py –¥–æ–¥–∞–π—Ç–µ:
@event.listens_for(Engine, "before_cursor_execute")
def receive_before_cursor_execute(conn, cursor, statement, params, context, executemany):
    conn.info.setdefault('query_start_time', []).append(time.time())

@event.listens_for(Engine, "after_cursor_execute")
def receive_after_cursor_execute(conn, cursor, statement, params, context, executemany):
    total = time.time() - conn.info['query_start_time'].pop(-1)
    if total > 5.0:  # –ë—ñ–ª—å—à–µ 5 —Å–µ–∫—É–Ω–¥
        logger.warning(f"Slow query detected: {total:.2f}s - {statement[:100]}")

# –£ search.py –¥–æ–¥–∞–π—Ç–µ –æ–±–º–µ–∂–µ–Ω–Ω—è:
MAX_KEYWORDS = 5
MAX_KEYWORD_LENGTH = 100

if filters_dict.get("keywords"):
    kws = [k.strip()[:MAX_KEYWORD_LENGTH] for k in filters_dict["keywords"].split(",") if k.strip()]
    kws = kws[:MAX_KEYWORDS]  # –û–±–º–µ–∂—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤
```

---

### 6. –ù–µ–±–µ–∑–ø–µ—á–Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è eval/exec –≤—ñ–¥—Å—É—Ç–Ω—î ‚úÖ –î–û–ë–†–ï

**–°—Ç–∞—Ç—É—Å:** –£ –∫–æ–¥—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è eval() –∞–±–æ exec(), —â–æ —î –≥–∞—Ä–Ω–æ—é –ø—Ä–∞–∫—Ç–∏–∫–æ—é.

---

### 7. –õ–æ–≥—É–≤–∞–Ω–Ω—è —á—É—Ç–ª–∏–≤–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó ‚ö†Ô∏è –°–ï–†–ï–î–ù–Ü–ô –†–ò–ó–ò–ö

**–ü—Ä–æ–±–ª–µ–º–∞:** –£ —Ñ–∞–π–ª—ñ `database/database.py` (—Ä—è–¥–æ–∫ 40) –ª–æ–≥—É—î—Ç—å—Å—è URL –±–∞–∑–∏ –¥–∞–Ω–∏—Ö, —è–∫–∏–π –º–æ–∂–µ –º—ñ—Å—Ç–∏—Ç–∏ –ø–∞—Ä–æ–ª—å.

**–í—Ä–∞–∑–ª–∏–≤—ñ—Å—Ç—å:**
```python
# –ù–ï–ë–ï–ó–ü–ï–ß–ù–û - –º–æ–∂–µ –ª–æ–≥—É–≤–∞—Ç–∏ –ø–∞—Ä–æ–ª—å
safe_url = db_url.split('@')[-1] if '@' in db_url else db_url
logger.info(f"–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –±–∞–∑–∏ –¥–∞–Ω–∏—Ö: {safe_url}")
```

**–í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:**
```python
# –ë–ï–ó–ü–ï–ß–ù–û - –º–∞—Å–∫—É—î–º–æ –≤—Å—é —á—É—Ç–ª–∏–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é
from urllib.parse import urlparse, urlunparse

def sanitize_db_url(url: str) -> str:
    """–í–∏–¥–∞–ª—è—î —á—É—Ç–ª–∏–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ URL –±–∞–∑–∏ –¥–∞–Ω–∏—Ö"""
    try:
        parsed = urlparse(url)
        # –ó–∞–º—ñ–Ω—é—î–º–æ –ø–∞—Ä–æ–ª—å –Ω–∞ –∑—ñ—Ä–æ—á–∫–∏
        if parsed.password:
            netloc = f"{parsed.username}:***@{parsed.hostname}"
            if parsed.port:
                netloc += f":{parsed.port}"
            sanitized = parsed._replace(netloc=netloc)
            return urlunparse(sanitized)
        return url.replace(parsed.password or "", "***") if parsed.password else url
    except Exception:
        return "***"  # –£ –≤–∏–ø–∞–¥–∫—É –ø–æ–º–∏–ª–∫–∏ –ø—Ä–∏—Ö–æ–≤—É—î–º–æ –≤—Å–µ

logger.info(f"–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –±–∞–∑–∏ –¥–∞–Ω–∏—Ö: {sanitize_db_url(db_url)}")
```

---

## ‚ö° –ü–†–û–î–£–ö–¢–ò–í–ù–Ü–°–¢–¨ (Performance Bottlenecks)

### 1. N+1 Query Problem ‚ùå –ö–†–ò–¢–ò–ß–ù–ò–ô –í–ü–õ–ò–í

**–ü—Ä–æ–±–ª–µ–º–∞:** –£ —Ñ–∞–π–ª—ñ `bot/handlers/search.py` (—Ä—è–¥–∫–∏ 269-277) –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏–π –∑–∞–ø–∏—Ç –¥–æ –ë–î –¥–ª—è –∫–æ–∂–Ω–æ—ó –≤–∞–∫–∞–Ω—Å—ñ—ó.

**–ù–µ–µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ:**
```python
# –í–∏–∫–æ–Ω—É—î—Ç—å—Å—è 2 –∑–∞–ø–∏—Ç–∏ –¥–ª—è –∫–æ–∂–Ω–æ—ó –≤–∞–∫–∞–Ω—Å—ñ—ó
job = db.query(JobListing).filter(JobListing.id == job_id).first()
db_user = db.query(User).filter(User.telegram_id == user_id).first()
favorite = db.query(UserFavorite).filter(...).first()
```

**–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è:**
```python
# –û–¥–∏–Ω –∑–∞–ø–∏—Ç –∑ JOIN
from sqlalchemy.orm import joinedload

# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤—Å–µ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø–∏—Ç
job = db.query(JobListing).options(
    joinedload(JobListing.favorites)
).filter(JobListing.id == job_id).first()

# –ö–µ—à—É—î–º–æ user –æ–±'—î–∫—Ç
if not hasattr(context, 'cached_user'):
    context.cached_user = db.query(User).filter(
        User.telegram_id == user_id
    ).first()
db_user = context.cached_user

# –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –≤ —É–ª—é–±–ª–µ–Ω–∏—Ö —á–µ—Ä–µ–∑ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –¥–∞–Ω—ñ
is_favorite = any(fav.user_id == db_user.id for fav in job.favorites) if db_user else False
```

---

### 2. –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å —ñ–Ω–¥–µ–∫—Å—ñ–≤ –Ω–∞ —á–∞—Å—Ç–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–Ω–∏—Ö –ø–æ–ª—è—Ö ‚ùå –í–ò–°–û–ö–ò–ô –í–ü–õ–ò–í

**–ü—Ä–æ–±–ª–µ–º–∞:** –£ —Ñ–∞–π–ª—ñ `database/models.py` –≤—ñ–¥—Å—É—Ç–Ω—ñ —Å–∫–ª–∞–¥–µ–Ω—ñ —ñ–Ω–¥–µ–∫—Å–∏ –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤.

**–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è:**
```python
# database/models.py - –¥–æ–¥–∞–π—Ç–µ —Å–∫–ª–∞–¥–µ–Ω—ñ —ñ–Ω–¥–µ–∫—Å–∏

from sqlalchemy import Index

class JobListing(Base):
    __tablename__ = "job_listings"
    
    # ... —ñ—Å–Ω—É—é—á—ñ –ø–æ–ª—è ...
    
    # –î–æ–¥–∞–π—Ç–µ —Å–∫–ª–∞–¥–µ–Ω—ñ —ñ–Ω–¥–µ–∫—Å–∏
    __table_args__ = (
        # –î–ª—è –ø–æ—à—É–∫—É –∑ —Ñ—ñ–ª—å—Ç—Ä–∞–º–∏
        Index('idx_active_city_category', 'is_active', 'city', 'category'),
        Index('idx_active_published', 'is_active', 'published_date'),
        Index('idx_source_active', 'source', 'is_active'),
        # –î–ª—è full-text search (PostgreSQL)
        # Index('idx_title_gin', 'title', postgresql_using='gin', postgresql_ops={'title': 'gin_trgm_ops'}),
    )

class SearchHistory(Base):
    __tablename__ = "search_history"
    
    # ... —ñ—Å–Ω—É—é—á—ñ –ø–æ–ª—è ...
    
    __table_args__ = (
        Index('idx_user_created', 'user_id', 'created_at'),
    )
```

**–ú—ñ–≥—Ä–∞—Ü—ñ—è –¥–ª—è –¥–æ–¥–∞–≤–∞–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å—ñ–≤:**
```bash
# –°—Ç–≤–æ—Ä—ñ—Ç—å –º—ñ–≥—Ä–∞—Ü—ñ—é:
alembic revision -m "Add composite indexes for performance"
```

```python
# –£ —Ñ–∞–π–ª—ñ –º—ñ–≥—Ä–∞—Ü—ñ—ó:
def upgrade():
    op.create_index('idx_active_city_category', 'job_listings', ['is_active', 'city', 'category'])
    op.create_index('idx_active_published', 'job_listings', ['is_active', 'published_date'])
    op.create_index('idx_source_active', 'job_listings', ['source', 'is_active'])
    op.create_index('idx_user_created', 'search_history', ['user_id', 'created_at'])

def downgrade():
    op.drop_index('idx_user_created', 'search_history')
    op.drop_index('idx_source_active', 'job_listings')
    op.drop_index('idx_active_published', 'job_listings')
    op.drop_index('idx_active_city_category', 'job_listings')
```

---

### 3. –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∏–π —Å–∫—Ä–∞–ø—ñ–Ω–≥ –±–ª–æ–∫—É—î event loop ‚ùå –í–ò–°–û–ö–ò–ô –í–ü–õ–ò–í

**–ü—Ä–æ–±–ª–µ–º–∞:** –£ —Ñ–∞–π–ª—ñ `scraper/base_scraper.py` (—Ä—è–¥–∫–∏ 25-43) —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ñ HTTP –∑–∞–ø–∏—Ç–∏ –±–ª–æ–∫—É—é—Ç—å event loop.

**–ù–µ–µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ:**
```python
# –ë–ª–æ–∫—É—é—á–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∏–π –∑–∞–ø–∏—Ç
response = self.session.get(url, timeout=30)
time.sleep(random.uniform(2, 5))  # –ë–ª–æ–∫—É—î –≤–µ—Å—å event loop!
```

**–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è:**
```python
# scraper/base_scraper.py
import aiohttp
import asyncio

class BaseScraper(ABC):
    def __init__(self, source_name: str, base_url: str):
        self.source_name = source_name
        self.base_url = base_url
        self.headers = {'User-Agent': settings.USER_AGENT}
    
    async def fetch_page(self, url: str, retries: int = 3) -> Optional[str]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ—Ç—Ä–∏–º—É—î HTML —Å—Ç–æ—Ä—ñ–Ω–∫—É"""
        async with aiohttp.ClientSession(headers=self.headers) as session:
            for attempt in range(retries):
                try:
                    async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
                        response.raise_for_status()
                        
                        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ –∑–∞—Ç—Ä–∏–º–∫–∞ - –Ω–µ –±–ª–æ–∫—É—î event loop
                        await asyncio.sleep(random.uniform(2, 5))
                        
                        return await response.text()
                except Exception as e:
                    logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ {url} (—Å–ø—Ä–æ–±–∞ {attempt + 1}/{retries}): {e}")
                    if attempt < retries - 1:
                        await asyncio.sleep(2 ** attempt)
                    else:
                        logger.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ {url} –ø—ñ—Å–ª—è {retries} —Å–ø—Ä–æ–±")
        return None
    
    @abstractmethod
    async def fetch_jobs(self, max_pages: int = 5) -> List[Dict]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ—Ç—Ä–∏–º—É—î —Å–ø–∏—Å–æ–∫ –≤–∞–∫–∞–Ω—Å—ñ–π"""
        pass
```

---

### 4. –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∫–µ—à—É–≤–∞–Ω–Ω—è –¥–ª—è —á–∞—Å—Ç–æ –∑–∞–ø–∏—Ç—É–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö ‚ö†Ô∏è –°–ï–†–ï–î–ù–Ü–ô –í–ü–õ–ò–í

**–ü—Ä–æ–±–ª–µ–º–∞:** –ö–æ–∂–µ–Ω –∑–∞–ø–∏—Ç –≤–∏–∫–æ–Ω—É—î SQL –∑–∞–ø–∏—Ç–∏, –Ω–∞–≤—ñ—Ç—å –¥–ª—è —Å—Ç–∞—Ç–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö.

**–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è:**
```python
# bot/utils/cache.py
from functools import lru_cache
from datetime import datetime, timedelta
import redis
from config import settings
import json
import pickle

class Cache:
    def __init__(self):
        if settings.REDIS_URL:
            self.redis_client = redis.from_url(settings.REDIS_URL)
            self.use_redis = True
        else:
            self.use_redis = False
            self._local_cache = {}
    
    def get(self, key: str):
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –∑–Ω–∞—á–µ–Ω–Ω—è –∑ –∫–µ—à—É"""
        if self.use_redis:
            value = self.redis_client.get(key)
            return pickle.loads(value) if value else None
        return self._local_cache.get(key)
    
    def set(self, key: str, value, ttl: int = 300):
        """–ó–±–µ—Ä–µ–≥—Ç–∏ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–µ—à –∑ TTL (—Å–µ–∫—É–Ω–¥–∏)"""
        if self.use_redis:
            self.redis_client.setex(key, ttl, pickle.dumps(value))
        else:
            self._local_cache[key] = value
            # –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫–µ—à—É –º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ –ª–æ–≥—ñ–∫—É –≤–∏–¥–∞–ª–µ–Ω–Ω—è —á–µ—Ä–µ–∑ TTL
    
    def delete(self, key: str):
        """–í–∏–¥–∞–ª–∏—Ç–∏ –∑–Ω–∞—á–µ–Ω–Ω—è –∑ –∫–µ—à—É"""
        if self.use_redis:
            self.redis_client.delete(key)
        else:
            self._local_cache.pop(key, None)

cache = Cache()

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤ search.py:
def get_user_cached(db: Session, telegram_id: int):
    cache_key = f"user:{telegram_id}"
    user = cache.get(cache_key)
    
    if not user:
        user = db.query(User).filter(User.telegram_id == telegram_id).first()
        if user:
            cache.set(cache_key, user, ttl=300)  # 5 —Ö–≤–∏–ª–∏–Ω
    
    return user

# –î–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –º—ñ—Å—Ç:
@lru_cache(maxsize=1)
def get_cities_list():
    """–ö–µ—à—É—î —Å–ø–∏—Å–æ–∫ –º—ñ—Å—Ç –≤ –ø–∞–º'—è—Ç—ñ"""
    from config.constants import POLISH_CITIES
    return POLISH_CITIES
```

---

### 5. –ù–µ–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–µ–ª–∏–∫–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ ‚ö†Ô∏è –°–ï–†–ï–î–ù–Ü–ô –í–ü–õ–ò–í

**–ü—Ä–æ–±–ª–µ–º–∞:** –£ —Ñ–∞–π–ª—ñ `bot/handlers/search.py` (—Ä—è–¥–æ–∫ 190) –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î—Ç—å—Å—è 50 —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –æ–¥—Ä–∞–∑—É –≤ –ø–∞–º'—è—Ç—å.

**–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è:**
```python
# –ü–∞–≥—ñ–Ω–∞—Ü—ñ—è –Ω–∞ —Ä—ñ–≤–Ω—ñ –ë–î –∑ –∫—É—Ä—Å–æ—Ä–∞–º–∏
def search_jobs_paginated(db: Session, filters: dict, page: int = 1, per_page: int = 10):
    """–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π –ø–æ—à—É–∫ –∑ –ø–∞–≥—ñ–Ω–∞—Ü—ñ—î—é"""
    offset = (page - 1) * per_page
    
    query = db.query(JobListing.id).filter(JobListing.is_active == True)
    
    # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ñ—ñ–ª—å—Ç—Ä–∏...
    
    # –û—Ç—Ä–∏–º—É—î–º–æ —Ç—ñ–ª—å–∫–∏ ID –¥–ª—è –ø–∞–≥—ñ–Ω–∞—Ü—ñ—ó (–Ω–∞–±–∞–≥–∞—Ç–æ —à–≤–∏–¥—à–µ)
    total_count = query.count()  # –ö–µ—à—É–π—Ç–µ —Ü–µ –∑–Ω–∞—á–µ–Ω–Ω—è
    job_ids = query.order_by(JobListing.published_date.desc())\
                   .offset(offset)\
                   .limit(per_page)\
                   .all()
    
    return [job_id[0] for job_id in job_ids], total_count

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
job_ids, total = search_jobs_paginated(db, filters_dict, page=1, per_page=10)
user_search_state[user_id] = {
    "filters": filters_dict,
    "jobs": job_ids,  # –¢—ñ–ª—å–∫–∏ ID, –Ω–µ –ø–æ–≤–Ω—ñ –æ–±'—î–∫—Ç–∏
    "total": total,
    "current_page": 1
}
```

---

### 6. –ü–∞–º'—è—Ç—å –≤–∏—Ç—ñ–∫–∞—î —á–µ—Ä–µ–∑ user_search_state ‚ö†Ô∏è –°–ï–†–ï–î–ù–Ü–ô –í–ü–õ–ò–í

**–ü—Ä–æ–±–ª–µ–º–∞:** –£ —Ñ–∞–π–ª—ñ `bot/handlers/search.py` (—Ä—è–¥–æ–∫ 16) –≥–ª–æ–±–∞–ª—å–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫ `user_search_state` –Ω—ñ–∫–æ–ª–∏ –Ω–µ –æ—á–∏—â–∞—î—Ç—å—Å—è.

**–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è:**
```python
# bot/handlers/search.py
from collections import OrderedDict
from datetime import datetime

class SearchStateManager:
    def __init__(self, max_size: int = 1000, ttl_seconds: int = 3600):
        self.states = OrderedDict()
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
    
    def get(self, user_id: int, default=None):
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–∞–Ω –∑ –ø–µ—Ä–µ–≤—ñ—Ä–∫–æ—é TTL"""
        if user_id in self.states:
            state, timestamp = self.states[user_id]
            if (datetime.now() - timestamp).total_seconds() < self.ttl_seconds:
                return state
            else:
                del self.states[user_id]
        return default
    
    def set(self, user_id: int, state):
        """–ó–±–µ—Ä–µ–≥—Ç–∏ —Å—Ç–∞–Ω –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –æ—á–∏—â–µ–Ω–Ω—è–º"""
        self.states[user_id] = (state, datetime.now())
        self.states.move_to_end(user_id)
        
        # –í–∏–¥–∞–ª—è—î–º–æ –Ω–∞–π—Å—Ç–∞—Ä—ñ—à—ñ –∑–∞–ø–∏—Å–∏ —è–∫—â–æ –ø–µ—Ä–µ–≤–∏—â–µ–Ω–æ –ª—ñ–º—ñ—Ç
        while len(self.states) > self.max_size:
            self.states.popitem(last=False)

# –ó–∞–º—ñ—Å—Ç—å –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–Ω–∏–∫–∞:
user_search_state_manager = SearchStateManager(max_size=1000, ttl_seconds=3600)

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
state = user_search_state_manager.get(user_id, {"filters": {}})
```

---

## üöÄ –ù–û–í–Ü –§–Ü–ß–Ü (Feature Suggestions)

### 1. –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω—ñ —Å–ø–æ–≤—ñ—â–µ–Ω–Ω—è –ø—Ä–æ –Ω–æ–≤—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó –∑–∞ –ø—ñ–¥–ø–∏—Å–∫–∞–º–∏

**–û–ø–∏—Å:** –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ —Å–ø–æ–≤—ñ—â–µ–Ω—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞–º –ø—Ä–æ –Ω–æ–≤—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó, —â–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—é—Ç—å —ó—Ö –ø—ñ–¥–ø–∏—Å–∫–∞–º.

**–†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
# bot/jobs/subscription_notifier.py
from telegram import Bot
from database.database import get_db
from database.models import UserSubscription, JobListing, User
from sqlalchemy.orm import Session
from sqlalchemy import and_
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

async def check_subscriptions_and_notify(bot: Bot):
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î –ø—ñ–¥–ø–∏—Å–∫–∏ —Ç–∞ –≤—ñ–¥–ø—Ä–∞–≤–ª—è—î —Å–ø–æ–≤—ñ—â–µ–Ω–Ω—è"""
    db_gen = get_db()
    db: Session = next(db_gen)
    
    try:
        # –û—Ç—Ä–∏–º—É—î–º–æ –∞–∫—Ç–∏–≤–Ω—ñ –ø—ñ–¥–ø–∏—Å–∫–∏
        subscriptions = db.query(UserSubscription).filter(
            UserSubscription.is_active == True
        ).all()
        
        for subscription in subscriptions:
            try:
                # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –Ω–æ–≤—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó (–∑–∞ –æ—Å—Ç–∞–Ω–Ω—é –≥–æ–¥–∏–Ω—É)
                query = db.query(JobListing).filter(
                    and_(
                        JobListing.is_active == True,
                        JobListing.scraped_at >= datetime.utcnow() - timedelta(hours=1)
                    )
                )
                
                # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ñ—ñ–ª—å—Ç—Ä–∏ –ø—ñ–¥–ø–∏—Å–∫–∏
                if subscription.city:
                    query = query.filter(JobListing.city == subscription.city)
                
                if subscription.category:
                    query = query.filter(JobListing.category == subscription.category)
                
                if subscription.salary_min:
                    query = query.filter(
                        JobListing.salary_min >= subscription.salary_min
                    )
                
                if subscription.keywords:
                    import json
                    keywords = json.loads(subscription.keywords)
                    for keyword in keywords:
                        query = query.filter(
                            JobListing.title.ilike(f"%{keyword}%")
                        )
                
                new_jobs = query.limit(5).all()
                
                if new_jobs:
                    # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ —Å–ø–æ–≤—ñ—â–µ–Ω–Ω—è
                    user = subscription.user
                    message = f"üîî <b>–ù–æ–≤—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó –∑–∞ –≤–∞—à–æ—é –ø—ñ–¥–ø–∏—Å–∫–æ—é!</b>\n\n"
                    
                    for job in new_jobs:
                        message += f"üìå <b>{job.title}</b>\n"
                        message += f"üè¢ {job.company or '–ù–µ –≤–∫–∞–∑–∞–Ω–æ'}\n"
                        message += f"üìç {job.location or job.city}\n"
                        if job.salary_min:
                            message += f"üí∞ –≤—ñ–¥ {job.salary_min} {job.salary_currency}\n"
                        message += f"üîó {job.url}\n\n"
                    
                    await bot.send_message(
                        chat_id=user.telegram_id,
                        text=message,
                        parse_mode="HTML",
                        disable_web_page_preview=True
                    )
                    
                    logger.info(f"Sent {len(new_jobs)} new jobs to user {user.telegram_id}")
                    
            except Exception as e:
                logger.error(f"Error processing subscription {subscription.id}: {e}")
                continue
    
    finally:
        try:
            next(db_gen, None)
        except StopIteration:
            pass

# –î–æ–¥–∞–π—Ç–µ –≤ main.py:
from bot.jobs.subscription_notifier import check_subscriptions_and_notify

async def post_init(application: Application):
    """–í–∏–∫–æ–Ω—É—î—Ç—å—Å—è –ø—ñ—Å–ª—è —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó –±–æ—Ç–∞"""
    logger.info("–ë–æ—Ç —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ")
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫ —Å–∫—Ä–∞–ø—ñ–Ω–≥—É
    if settings.SCRAPING_ENABLED:
        scheduler = ScrapingScheduler()
        scheduler.start()
        application.bot_data['scheduler'] = scheduler
    
    # –î–æ–¥–∞—î–º–æ –∑–∞–¥–∞—á—É –¥–ª—è —Å–ø–æ–≤—ñ—â–µ–Ω—å –ø—Ä–æ –ø—ñ–¥–ø–∏—Å–∫–∏
    job_queue = application.job_queue
    job_queue.run_repeating(
        lambda context: check_subscriptions_and_notify(context.bot),
        interval=3600,  # –ö–æ–∂–Ω—É –≥–æ–¥–∏–Ω—É
        first=60  # –ü–µ—Ä—à–∏–π –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ 1 —Ö–≤–∏–ª–∏–Ω—É
    )
```

---

### 2. –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ —ñ—Å—Ç–æ—Ä—ñ—ó –ø–æ—à—É–∫—É

**–û–ø–∏—Å:** –î–æ–¥–∞—Ç–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –≤–∞–∫–∞–Ω—Å—ñ–π –Ω–∞ –æ—Å–Ω–æ–≤—ñ —ñ—Å—Ç–æ—Ä—ñ—ó –ø–æ—à—É–∫—ñ–≤ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞.

**–†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
# bot/utils/recommendations.py
from database.models import SearchHistory, JobListing, User
from sqlalchemy.orm import Session
from sqlalchemy import func, desc
from collections import Counter
from typing import List
import json

def get_user_recommendations(db: Session, user: User, limit: int = 10) -> List[JobListing]:
    """–û—Ç—Ä–∏–º—É—î —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ —ñ—Å—Ç–æ—Ä—ñ—ó"""
    
    # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —ñ—Å—Ç–æ—Ä—ñ—é –ø–æ—à—É–∫—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (–∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ–π –º—ñ—Å—è—Ü—å)
    from datetime import datetime, timedelta
    one_month_ago = datetime.utcnow() - timedelta(days=30)
    
    history = db.query(SearchHistory).filter(
        SearchHistory.user_id == user.id,
        SearchHistory.created_at >= one_month_ago
    ).all()
    
    if not history:
        # –Ø–∫—â–æ –Ω–µ–º–∞—î —ñ—Å—Ç–æ—Ä—ñ—ó, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ–ø—É–ª—è—Ä–Ω—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó
        return get_popular_jobs(db, limit)
    
    # –ó–±–∏—Ä–∞—î–º–æ —ñ–Ω—Ç–µ—Ä–µ—Å–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    all_queries = []
    all_cities = []
    all_categories = []
    
    for entry in history:
        if entry.query:
            all_queries.append(entry.query.lower())
        
        if entry.filters:
            if isinstance(entry.filters, str):
                filters = json.loads(entry.filters)
            else:
                filters = entry.filters
            
            if filters.get('city'):
                all_cities.append(filters['city'])
            if filters.get('category'):
                all_categories.append(filters['category'])
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –Ω–∞–π—á–∞—Å—Ç—ñ—à—ñ —ñ–Ω—Ç–µ—Ä–µ—Å–∏
    query_counter = Counter(all_queries)
    city_counter = Counter(all_cities)
    category_counter = Counter(all_categories)
    
    top_queries = [q for q, _ in query_counter.most_common(3)]
    top_city = city_counter.most_common(1)[0][0] if all_cities else None
    top_category = category_counter.most_common(1)[0][0] if all_categories else None
    
    # –§–æ—Ä–º—É—î–º–æ –∑–∞–ø–∏—Ç –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
    query = db.query(JobListing).filter(JobListing.is_active == True)
    
    # –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç 1: –º—ñ—Å—Ç–æ —Ç–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è
    if top_city and top_category:
        query = query.filter(
            JobListing.city == top_city,
            JobListing.category == top_category
        )
    elif top_city:
        query = query.filter(JobListing.city == top_city)
    elif top_category:
        query = query.filter(JobListing.category == top_category)
    
    # –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç 2: –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
    if top_queries:
        from sqlalchemy import or_
        keyword_filters = []
        for kw in top_queries:
            keyword_filters.append(JobListing.title.ilike(f"%{kw}%"))
            keyword_filters.append(JobListing.description.ilike(f"%{kw}%"))
        query = query.filter(or_(*keyword_filters))
    
    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –Ω–æ–≤–∏–∑–Ω–æ—é
    jobs = query.order_by(desc(JobListing.published_date)).limit(limit).all()
    
    return jobs

def get_popular_jobs(db: Session, limit: int = 10) -> List[JobListing]:
    """–ü–æ–≤–µ—Ä—Ç–∞—î –ø–æ–ø—É–ª—è—Ä–Ω—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó (–Ω–∞–π–±—ñ–ª—å—à–µ –ø–µ—Ä–µ–≥–ª—è–¥—ñ–≤)"""
    # –ú–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ –ø–æ–ª–µ views –¥–æ –º–æ–¥–µ–ª—ñ JobListing
    return db.query(JobListing).filter(
        JobListing.is_active == True
    ).order_by(desc(JobListing.published_date)).limit(limit).all()

# –î–æ–¥–∞–π—Ç–µ handler:
# bot/handlers/recommendations.py
from bot.utils.recommendations import get_user_recommendations
from bot.keyboards.main_menu import get_back_to_menu_keyboard
from bot.utils.formatters import format_job_listing

async def recommendations_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–æ–±–Ω–∏–∫ –∫–æ–º–∞–Ω–¥–∏ /recommendations"""
    user_id = update.effective_user.id
    
    with get_db_session() as db:
        db_user = db.query(User).filter(User.telegram_id == user_id).first()
        
        if not db_user:
            await update.message.reply_text(
                "‚ùå –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ /start"
            )
            return
        
        jobs = get_user_recommendations(db, db_user, limit=10)
        
        if not jobs:
            await update.message.reply_text(
                "üìä –ü–æ–∫–∏ —â–æ –Ω–µ–º–∞—î —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π. –°–ø—Ä–æ–±—É–π—Ç–µ –ø–æ—à—É–∫–∞—Ç–∏ –≤–∞–∫–∞–Ω—Å—ñ—ó!",
                reply_markup=get_back_to_menu_keyboard()
            )
            return
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –¥–ª—è –ø–∞–≥—ñ–Ω–∞—Ü—ñ—ó
        user_search_state[user_id] = {
            "jobs": [job.id for job in jobs],
            "current_page": 1,
            "filters": {}
        }
        
        await show_job_page(update, context, user_id, 1)
```

---

### 3. –ï–∫—Å–ø–æ—Ä—Ç –≤–∞–∫–∞–Ω—Å—ñ–π —É PDF/Excel

**–û–ø–∏—Å:** –î–æ–∑–≤–æ–ª–∏—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞–º –µ–∫—Å–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ –∑–Ω–∞–π–¥–µ–Ω—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó –∞–±–æ –æ–±—Ä–∞–Ω—ñ –≤ PDF –∞–±–æ Excel —Ñ–æ—Ä–º–∞—Ç—ñ.

**–†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
# bot/utils/export.py
from reportlab.lib.pagesizes import letter, A4
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
from reportlab.lib.units import inch
import io
from typing import List
from database.models import JobListing
import pandas as pd

def export_jobs_to_pdf(jobs: List[JobListing]) -> io.BytesIO:
    """–ï–∫—Å–ø–æ—Ä—Ç—É—î –≤–∞–∫–∞–Ω—Å—ñ—ó —É PDF"""
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    styles = getSampleStyleSheet()
    story = []
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    title = Paragraph("–í–∞–∫–∞–Ω—Å—ñ—ó WorkSearchBot", styles['Title'])
    story.append(title)
    story.append(Spacer(1, 0.2*inch))
    
    for job in jobs:
        # –ù–∞–∑–≤–∞ –≤–∞–∫–∞–Ω—Å—ñ—ó
        job_title = Paragraph(f"<b>{job.title}</b>", styles['Heading2'])
        story.append(job_title)
        
        # –î–µ—Ç–∞–ª—ñ
        details = f"""
        <b>–ö–æ–º–ø–∞–Ω—ñ—è:</b> {job.company or '–ù–µ –≤–∫–∞–∑–∞–Ω–æ'}<br/>
        <b>–õ–æ–∫–∞—Ü—ñ—è:</b> {job.location or job.city or '–ù–µ –≤–∫–∞–∑–∞–Ω–æ'}<br/>
        """
        
        if job.salary_min or job.salary_max:
            salary_text = f"–≤—ñ–¥ {job.salary_min}" if job.salary_min else ""
            if job.salary_max:
                salary_text += f" –¥–æ {job.salary_max}"
            salary_text += f" {job.salary_currency}"
            details += f"<b>–ó–∞—Ä–ø–ª–∞—Ç–∞:</b> {salary_text}<br/>"
        
        details += f"<b>–ü–æ—Å–∏–ª–∞–Ω–Ω—è:</b> {job.url}<br/>"
        
        details_p = Paragraph(details, styles['Normal'])
        story.append(details_p)
        
        # –û–ø–∏—Å
        if job.description:
            desc_text = job.description[:500] + "..." if len(job.description) > 500 else job.description
            desc = Paragraph(f"<b>–û–ø–∏—Å:</b> {desc_text}", styles['Normal'])
            story.append(desc)
        
        story.append(Spacer(1, 0.3*inch))
    
    doc.build(story)
    buffer.seek(0)
    return buffer

def export_jobs_to_excel(jobs: List[JobListing]) -> io.BytesIO:
    """–ï–∫—Å–ø–æ—Ä—Ç—É—î –≤–∞–∫–∞–Ω—Å—ñ—ó —É Excel"""
    data = []
    
    for job in jobs:
        data.append({
            '–ù–∞–∑–≤–∞': job.title,
            '–ö–æ–º–ø–∞–Ω—ñ—è': job.company or '–ù–µ –≤–∫–∞–∑–∞–Ω–æ',
            '–õ–æ–∫–∞—Ü—ñ—è': job.location or job.city,
            '–ú—ñ—Å—Ç–æ': job.city,
            '–ú—ñ–Ω. –∑–∞—Ä–ø–ª–∞—Ç–∞': job.salary_min,
            '–ú–∞–∫—Å. –∑–∞—Ä–ø–ª–∞—Ç–∞': job.salary_max,
            '–í–∞–ª—é—Ç–∞': job.salary_currency,
            '–¢–∏–ø –∑–∞–π–Ω—è—Ç–æ—Å—Ç—ñ': job.employment_type,
            '–ö–∞—Ç–µ–≥–æ—Ä—ñ—è': job.category,
            '–ü–æ—Å–∏–ª–∞–Ω–Ω—è': job.url,
            '–î–∞—Ç–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó': job.published_date.strftime('%Y-%m-%d') if job.published_date else ''
        })
    
    df = pd.DataFrame(data)
    buffer = io.BytesIO()
    
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='–í–∞–∫–∞–Ω—Å—ñ—ó')
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —à–∏—Ä–∏–Ω–∏ –∫–æ–ª–æ–Ω–æ–∫
        worksheet = writer.sheets['–í–∞–∫–∞–Ω—Å—ñ—ó']
        for i, col in enumerate(df.columns):
            max_length = max(df[col].astype(str).apply(len).max(), len(col)) + 2
            worksheet.set_column(i, i, min(max_length, 50))
    
    buffer.seek(0)
    return buffer

# bot/handlers/export.py
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import ContextTypes
from bot.utils.export import export_jobs_to_pdf, export_jobs_to_excel
from database.models import JobListing, UserFavorite, User

async def export_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–æ–±–Ω–∏–∫ –∫–æ–º–∞–Ω–¥–∏ /export"""
    keyboard = [
        [
            InlineKeyboardButton("üìÑ PDF", callback_data="export_pdf"),
            InlineKeyboardButton("üìä Excel", callback_data="export_excel")
        ],
        [InlineKeyboardButton("¬´ –ù–∞–∑–∞–¥", callback_data="main_menu")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    text = "üì§ <b>–ï–∫—Å–ø–æ—Ä—Ç –≤–∞–∫–∞–Ω—Å—ñ–π</b>\n\n–û–±–µ—Ä—ñ—Ç—å —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É –≤–∞—à–∏—Ö –æ–±—Ä–∞–Ω–∏—Ö –≤–∞–∫–∞–Ω—Å—ñ–π:"
    
    if update.callback_query:
        await update.callback_query.edit_message_text(
            text,
            reply_markup=reply_markup,
            parse_mode="HTML"
        )
    else:
        await update.message.reply_text(
            text,
            reply_markup=reply_markup,
            parse_mode="HTML"
        )

async def export_callback_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–æ–±–Ω–∏–∫ callbacks –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É"""
    query = update.callback_query
    await query.answer()
    
    user_id = update.effective_user.id
    
    with get_db_session() as db:
        db_user = db.query(User).filter(User.telegram_id == user_id).first()
        
        if not db_user:
            await query.edit_message_text("‚ùå –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
            return
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –æ–±—Ä–∞–Ω—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó
        favorites = db.query(UserFavorite).filter(
            UserFavorite.user_id == db_user.id
        ).all()
        
        if not favorites:
            await query.edit_message_text(
                "‚ùå –£ –≤–∞—Å –Ω–µ–º–∞—î –æ–±—Ä–∞–Ω–∏—Ö –≤–∞–∫–∞–Ω—Å—ñ–π –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É.\n"
                "–°–ø–æ—á–∞—Ç–∫—É –¥–æ–¥–∞–π—Ç–µ –≤–∞–∫–∞–Ω—Å—ñ—ó –¥–æ –æ–±—Ä–∞–Ω–∏—Ö."
            )
            return
        
        jobs = [fav.job_listing for fav in favorites]
        
        await query.edit_message_text("‚è≥ –ì–µ–Ω–µ—Ä—É—é —Ñ–∞–π–ª...")
        
        try:
            if query.data == "export_pdf":
                buffer = export_jobs_to_pdf(jobs)
                filename = f"vacancies_{user_id}.pdf"
                
                await context.bot.send_document(
                    chat_id=user_id,
                    document=buffer,
                    filename=filename,
                    caption=f"üìÑ –í–∞—à—ñ –æ–±—Ä–∞–Ω—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó ({len(jobs)} —à—Ç.)"
                )
            
            elif query.data == "export_excel":
                buffer = export_jobs_to_excel(jobs)
                filename = f"vacancies_{user_id}.xlsx"
                
                await context.bot.send_document(
                    chat_id=user_id,
                    document=buffer,
                    filename=filename,
                    caption=f"üìä –í–∞—à—ñ –æ–±—Ä–∞–Ω—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó ({len(jobs)} —à—Ç.)"
                )
            
            await query.message.reply_text("‚úÖ –§–∞–π–ª —É—Å–ø—ñ—à–Ω–æ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ!")
            
        except Exception as e:
            logger.error(f"Error exporting: {e}")
            await query.message.reply_text("‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –µ–∫—Å–ø–æ—Ä—Ç—ñ —Ñ–∞–π–ª—É")

# –î–æ–¥–∞–π—Ç–µ –≤ requirements.txt:
# reportlab==4.0.7
# pandas==2.1.3
# openpyxl==3.1.2
# xlsxwriter==3.1.9
```

---

### 4. –†–æ–∑—à–∏—Ä–µ–Ω–∏–π –ø–æ—à—É–∫ –∑ AI/ML –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é

**–û–ø–∏—Å:** –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è NLP –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—ñ –ø–æ—à—É–∫—É —Ç–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ—ó –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü—ñ—ó –≤–∞–∫–∞–Ω—Å—ñ–π.

**–†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
# bot/utils/ai_search.py
from typing import List, Dict
from database.models import JobListing
from sqlalchemy.orm import Session

# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ sentence-transformers –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É
try:
    from sentence_transformers import SentenceTransformer, util
    import torch
    AI_SEARCH_AVAILABLE = True
except ImportError:
    AI_SEARCH_AVAILABLE = False

class AIJobSearcher:
    def __init__(self):
        if not AI_SEARCH_AVAILABLE:
            raise ImportError("Install sentence-transformers: pip install sentence-transformers")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å (–º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ multilingual –º–æ–¥–µ–ª—å)
        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        self.job_embeddings_cache = {}
    
    def encode_jobs(self, jobs: List[JobListing]) -> Dict[int, torch.Tensor]:
        """–°—Ç–≤–æ—Ä—é—î –≤–µ–∫—Ç–æ—Ä–Ω—ñ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –¥–ª—è –≤–∞–∫–∞–Ω—Å—ñ–π"""
        embeddings = {}
        
        for job in jobs:
            if job.id in self.job_embeddings_cache:
                embeddings[job.id] = self.job_embeddings_cache[job.id]
                continue
            
            # –ö–æ–º–±—ñ–Ω—É—î–º–æ –Ω–∞–∑–≤—É, –æ–ø–∏—Å —Ç–∞ –∫–æ–º–ø–∞–Ω—ñ—é
            text = f"{job.title}. {job.description or ''}. {job.company or ''}"
            embedding = self.model.encode(text, convert_to_tensor=True)
            
            embeddings[job.id] = embedding
            self.job_embeddings_cache[job.id] = embedding
        
        return embeddings
    
    def semantic_search(self, query: str, jobs: List[JobListing], top_k: int = 10) -> List[JobListing]:
        """–°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫ –≤–∞–∫–∞–Ω—Å—ñ–π"""
        if not jobs:
            return []
        
        # –ö–æ–¥—É—î–º–æ –∑–∞–ø–∏—Ç
        query_embedding = self.model.encode(query, convert_to_tensor=True)
        
        # –ö–æ–¥—É—î–º–æ –≤–∞–∫–∞–Ω—Å—ñ—ó
        job_embeddings = self.encode_jobs(jobs)
        
        # –û–±—á–∏—Å–ª—é—î–º–æ –ø–æ–¥—ñ–±–Ω—ñ—Å—Ç—å
        job_ids = list(job_embeddings.keys())
        embeddings_tensor = torch.stack([job_embeddings[jid] for jid in job_ids])
        
        cos_scores = util.cos_sim(query_embedding, embeddings_tensor)[0]
        
        # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—é
        top_results = torch.topk(cos_scores, k=min(top_k, len(jobs)))
        
        # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –Ω–∞–π—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—à—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó
        result_jobs = [jobs[idx] for idx in top_results.indices]
        
        return result_jobs

# –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –≤ search.py:
ai_searcher = AIJobSearcher() if AI_SEARCH_AVAILABLE else None

async def ai_search_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–æ–±–Ω–∏–∫ AI –ø–æ—à—É–∫—É"""
    if not AI_SEARCH_AVAILABLE:
        await update.message.reply_text(
            "‚ùå AI –ø–æ—à—É–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π. –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ:\n"
            "pip install sentence-transformers torch"
        )
        return
    
    query_text = update.message.text.strip()
    user_id = update.effective_user.id
    
    with get_db_session() as db:
        # –û—Ç—Ä–∏–º—É—î–º–æ –≤—Å—ñ –∞–∫—Ç–∏–≤–Ω—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó (–∞–±–æ –∑ —Ñ—ñ–ª—å—Ç—Ä–∞–º–∏)
        jobs = db.query(JobListing).filter(
            JobListing.is_active == True
        ).limit(100).all()  # –û–±–º–µ–∂—É—î–º–æ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
        
        if not jobs:
            await update.message.reply_text("‚ùå –ù–µ–º–∞—î –∞–∫—Ç–∏–≤–Ω–∏—Ö –≤–∞–∫–∞–Ω—Å—ñ–π")
            return
        
        await update.message.reply_text("ü§ñ –®—É–∫–∞—é –Ω–∞–π–∫—Ä–∞—â—ñ –∑–±—ñ–≥–∏ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é AI...")
        
        # –í–∏–∫–æ–Ω—É—î–º–æ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫
        import asyncio
        relevant_jobs = await asyncio.to_thread(
            ai_searcher.semantic_search,
            query_text,
            jobs,
            top_k=10
        )
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        user_search_state[user_id] = {
            "jobs": [job.id for job in relevant_jobs],
            "current_page": 1,
            "filters": {}
        }
        
        await show_job_page(update, context, user_id, 1)

# –î–æ–¥–∞–π—Ç–µ –≤ requirements.txt:
# sentence-transformers==2.2.2
# torch==2.1.0
```

---

### 5. Telegram Web App —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è

**–û–ø–∏—Å:** –°—Ç–≤–æ—Ä–∏—Ç–∏ Web App –¥–ª—è –±—ñ–ª—å—à –∑—Ä—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É –ø–æ—à—É–∫—É —Ç–∞ –ø–µ—Ä–µ–≥–ª—è–¥—É –≤–∞–∫–∞–Ω—Å—ñ–π.

**–†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
# bot/webapp/app.py
from flask import Flask, render_template, request, jsonify
from database.database import get_db
from database.models import JobListing
from sqlalchemy import or_

app = Flask(__name__)

@app.route('/')
def index():
    """–ì–æ–ª–æ–≤–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ Web App"""
    return render_template('index.html')

@app.route('/api/search')
def api_search():
    """API –¥–ª—è –ø–æ—à—É–∫—É –≤–∞–∫–∞–Ω—Å—ñ–π"""
    query = request.args.get('q', '')
    city = request.args.get('city', '')
    category = request.args.get('category', '')
    page = int(request.args.get('page', 1))
    per_page = 20
    
    db_gen = get_db()
    db = next(db_gen)
    
    try:
        db_query = db.query(JobListing).filter(JobListing.is_active == True)
        
        if query:
            db_query = db_query.filter(
                or_(
                    JobListing.title.ilike(f"%{query}%"),
                    JobListing.description.ilike(f"%{query}%")
                )
            )
        
        if city:
            db_query = db_query.filter(JobListing.city == city)
        
        if category:
            db_query = db_query.filter(JobListing.category == category)
        
        total = db_query.count()
        jobs = db_query.offset((page - 1) * per_page).limit(per_page).all()
        
        return jsonify({
            'jobs': [
                {
                    'id': job.id,
                    'title': job.title,
                    'company': job.company,
                    'location': job.location or job.city,
                    'salary_min': float(job.salary_min) if job.salary_min else None,
                    'salary_max': float(job.salary_max) if job.salary_max else None,
                    'salary_currency': job.salary_currency,
                    'url': job.url,
                    'published_date': job.published_date.isoformat() if job.published_date else None
                }
                for job in jobs
            ],
            'total': total,
            'page': page,
            'pages': (total + per_page - 1) // per_page
        })
    finally:
        try:
            next(db_gen, None)
        except StopIteration:
            pass

# bot/webapp/templates/index.html
"""
<!DOCTYPE html>
<html>
<head>
    <title>WorkSearchBot</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://telegram.org/js/telegram-web-app.js"></script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto;
            margin: 0;
            padding: 20px;
            background: var(--tg-theme-bg-color);
            color: var(--tg-theme-text-color);
        }
        .search-box {
            width: 100%;
            padding: 12px;
            margin-bottom: 20px;
            border: 1px solid var(--tg-theme-hint-color);
            border-radius: 8px;
            font-size: 16px;
        }
        .job-card {
            background: var(--tg-theme-secondary-bg-color);
            padding: 15px;
            margin-bottom: 15px;
            border-radius: 10px;
        }
        .job-title {
            font-size: 18px;
            font-weight: bold;
            margin-bottom: 5px;
        }
        .job-company {
            color: var(--tg-theme-hint-color);
            margin-bottom: 5px;
        }
        .job-location {
            margin-bottom: 5px;
        }
        .job-salary {
            color: var(--tg-theme-link-color);
            font-weight: bold;
        }
    </style>
</head>
<body>
    <input type="text" id="searchBox" class="search-box" placeholder="–ü–æ—à—É–∫ –≤–∞–∫–∞–Ω—Å—ñ–π...">
    <div id="results"></div>
    
    <script>
        let tg = window.Telegram.WebApp;
        tg.expand();
        
        const searchBox = document.getElementById('searchBox');
        const resultsDiv = document.getElementById('results');
        
        let searchTimeout;
        searchBox.addEventListener('input', () => {
            clearTimeout(searchTimeout);
            searchTimeout = setTimeout(search, 500);
        });
        
        async function search() {
            const query = searchBox.value;
            const response = await fetch(`/api/search?q=${encodeURIComponent(query)}`);
            const data = await response.json();
            
            resultsDiv.innerHTML = '';
            data.jobs.forEach(job => {
                const card = document.createElement('div');
                card.className = 'job-card';
                card.innerHTML = `
                    <div class="job-title">${job.title}</div>
                    <div class="job-company">${job.company || '–ö–æ–º–ø–∞–Ω—ñ—è –Ω–µ –≤–∫–∞–∑–∞–Ω–∞'}</div>
                    <div class="job-location">üìç ${job.location || '–õ–æ–∫–∞—Ü—ñ—è –Ω–µ –≤–∫–∞–∑–∞–Ω–∞'}</div>
                    ${job.salary_min ? `<div class="job-salary">üí∞ –≤—ñ–¥ ${job.salary_min} ${job.salary_currency}</div>` : ''}
                `;
                card.onclick = () => tg.openLink(job.url);
                resultsDiv.appendChild(card);
            });
        }
        
        search();
    </script>
</body>
</html>
"""

# –î–æ–¥–∞–π—Ç–µ –∫–Ω–æ–ø–∫—É Web App –≤ keyboards:
# bot/keyboards/main_menu.py
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, WebAppInfo

def get_main_menu_keyboard():
    keyboard = [
        [
            InlineKeyboardButton("üîç –ü–æ—à—É–∫", callback_data="search"),
            InlineKeyboardButton("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", callback_data="stats")
        ],
        [
            InlineKeyboardButton("‚≠ê –û–±—Ä–∞–Ω—ñ", callback_data="favorites"),
            InlineKeyboardButton("üîî –ü—ñ–¥–ø–∏—Å–∫–∏", callback_data="subscriptions")
        ],
        [
            InlineKeyboardButton("‚öôÔ∏è –§—ñ–ª—å—Ç—Ä–∏", callback_data="filters"),
            InlineKeyboardButton("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó", callback_data="recommendations")
        ],
        [
            InlineKeyboardButton(
                "üåê Web App",
                web_app=WebAppInfo(url="https://your-webapp-url.com")
            )
        ]
    ]
    return InlineKeyboardMarkup(keyboard)

# –î–æ–¥–∞–π—Ç–µ –≤ requirements.txt:
# flask==3.0.0
```

---

## üìã –ü–Ü–î–°–£–ú–û–ö

### –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–∏ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω—å:

**üî¥ –ö—Ä–∏—Ç–∏—á–Ω—ñ (–≤–∏–ø—Ä–∞–≤–∏—Ç–∏ –Ω–µ–≥–∞–π–Ω–æ):**
1. SQL Injection —á–µ—Ä–µ–∑ ILIKE –∑–∞–ø–∏—Ç–∏
2. –í—ñ–¥–∫—Ä–∏—Ç–∏–π –¥–æ—Å—Ç—É–ø –¥–æ —Å–µ–∫—Ä–µ—Ç–Ω–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤
3. N+1 Query Problem

**üü° –í–∏—Å–æ–∫—ñ (–≤–∏–ø—Ä–∞–≤–∏—Ç–∏ –Ω–∞–π–±–ª–∏–∂—á–∏–º —á–∞—Å–æ–º):**
1. –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–æ–≥–æ –≤–≤–æ–¥—É
2. –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å —ñ–Ω–¥–µ–∫—Å—ñ–≤ –Ω–∞ —á–∞—Å—Ç–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–Ω–∏—Ö –ø–æ–ª—è—Ö
3. –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∏–π —Å–∫—Ä–∞–ø—ñ–Ω–≥ –±–ª–æ–∫—É—î event loop

**üü¢ –°–µ—Ä–µ–¥–Ω—ñ (–º–æ–∂–Ω–∞ –≤—ñ–¥–∫–ª–∞—Å—Ç–∏):**
1. –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å rate limiting
2. –ü–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∞ DoS —á–µ—Ä–µ–∑ –Ω–µ–æ–±–º–µ–∂–µ–Ω–∏–π –∑–∞–ø–∏—Ç –¥–æ –ë–î
3. –õ–æ–≥—É–≤–∞–Ω–Ω—è —á—É—Ç–ª–∏–≤–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó
4. –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∫–µ—à—É–≤–∞–Ω–Ω—è
5. –ù–µ–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
6. –í–∏—Ç—ñ–∫ –ø–∞–º'—è—Ç—ñ —á–µ—Ä–µ–∑ user_search_state

### –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ñ –Ω–æ–≤—ñ —Ñ—ñ—á—ñ (–∑–∞ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–æ–º):

1. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω—ñ —Å–ø–æ–≤—ñ—â–µ–Ω–Ω—è –ø—Ä–æ –Ω–æ–≤—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó** - –Ω–∞–π–±—ñ–ª—å—à –∫–æ—Ä–∏—Å–Ω–∞ —Ñ—ñ—á–∞ –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
2. **–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó** - –ø–æ–∫—Ä–∞—â—É—î UX —Ç–∞ retention
3. **–ï–∫—Å–ø–æ—Ä—Ç —É PDF/Excel** - –¥–æ–¥–∞—î —Ü—ñ–Ω–Ω–æ—Å—Ç—ñ –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
4. **–†–æ–∑—à–∏—Ä–µ–Ω–∏–π –ø–æ—à—É–∫ –∑ AI** - –¥–∏—Ñ–µ—Ä–µ–Ω—Ü—ñ—é—î –≤—ñ–¥ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤
5. **Telegram Web App** - —Å—É—á–∞—Å–Ω–∏–π UX –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –≤–∑–∞—î–º–æ–¥—ñ–π

---

**–ê–≤—Ç–æ—Ä:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∫–æ–¥—É WorkSearchBot  
**–î–∞—Ç–∞:** 2026-02-01
